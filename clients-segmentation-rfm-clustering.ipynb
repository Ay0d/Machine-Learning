{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/mickaelnarboni/clients-segmentation-rfm-clustering?scriptVersionId=89231292\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Table of Contents\n\n* [Marketing Goals](#marketing-goals)\n* [RFM Clustering](#rfm-clustering)\n  - [Recency](#recency)\n  - [Frequency](#frequency)\n  - [Monetary Value](#monetary-value)\n* [RFM Normalization](#rfm-normalization)\n* [Customers Segmentation](#customers-segmentation)\n* [Graphic Representations](#graphic-representations)\n* [Prepare for Production](#production)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"marketing-goals\"></a>\n## Marketing Goals\n\n**RFM** stands for **Recency - Frequency - Monetary Value**. \n\nTheoretically we will have segments like below:\n\n- Low Value: Customers who are less active than others, not very frequent buyer/visitor and generates very low zero - maybe negative revenue.\n\n- Mid Value: In the middle of everything. Often using our platform (but not as much as our High Values), fairly frequent and generates moderate revenue.\n\n- High Value: The group we donâ€™t want to lose. High Revenue, Frequency and low Inactivity.\n","metadata":{}},{"cell_type":"markdown","source":"Importing the relevant libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\") # ignore the warnings about file size\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n%matplotlib inline\nimport seaborn as sns\nfrom time import process_time\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score\nimport math\nfrom sklearn.metrics import adjusted_rand_score\nimport plotly.io as pio\npio.renderers.default = 'iframe'\nimport scipy.cluster.hierarchy as shc\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import Birch\nfrom sklearn.cluster import SpectralClustering\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.cluster import MiniBatchKMeans\nfrom yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\nfrom yellowbrick.contrib.scatter import ScatterVisualizer\nimport plotly.offline as pyoff\nimport plotly.graph_objs as go\nimport plotly.express as px\n!pip install plotly\n!pip install -U kaleido\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-03-03T23:03:11.463596Z","iopub.execute_input":"2022-03-03T23:03:11.464211Z","iopub.status.idle":"2022-03-03T23:03:31.618869Z","shell.execute_reply.started":"2022-03-03T23:03:11.464082Z","shell.execute_reply":"2022-03-03T23:03:31.617684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Importing each CSV file into different dataframes.","metadata":{}},{"cell_type":"code","source":"geolocation = pd.read_csv('../input/olist-clients-segmentation/geolocation_p4.csv',sep='\\t', index_col=[0], low_memory=False)\ndf = pd.read_csv('../input/olist-clients-segmentation/database_p4.csv',sep='\\t', index_col=[0], low_memory=False)\ndf\n# important note: adding  index_col=[0] allows to avoid having a column \"Unnamed:0\"","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:31.621446Z","iopub.execute_input":"2022-03-03T23:03:31.621705Z","iopub.status.idle":"2022-03-03T23:03:35.375258Z","shell.execute_reply.started":"2022-03-03T23:03:31.621676Z","shell.execute_reply":"2022-03-03T23:03:35.374303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Option to display all columns.","metadata":{}},{"cell_type":"code","source":"pd.set_option(\"display.max_columns\", None)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:35.376904Z","iopub.execute_input":"2022-03-03T23:03:35.377252Z","iopub.status.idle":"2022-03-03T23:03:35.419494Z","shell.execute_reply.started":"2022-03-03T23:03:35.377183Z","shell.execute_reply":"2022-03-03T23:03:35.418434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"rfm-clustering\"></a>\n## RFM Clustering\n\nWe'll use a method well-known in marketing to do customers segmentation, it is called RFM for Recency, Frequency, Monetary Value.\n\nIt relies on creating a cluster for each variable.\nFor the recency, we get the days of the last purchase date for each customer.\nFor the frequency, we can get the number of orders of each customer.\nFor the revenue, we'll use the price per order per customer.\n\nThen, we use the Elbow method for each variable to see what is the best number of hyperparameters (in this case K for number of clusters) to do our segmentation.\nWe get a value of K=4 most fo the time and we use Kmeans clustering because this is the most accurate and commonly used method for RFM segmentation. \n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"recency\"></a>\n### Recency","metadata":{}},{"cell_type":"markdown","source":"Converting the order date from string to time ","metadata":{}},{"cell_type":"code","source":"#convert the string date field to datetime\n\ndf['order_purchase_timestamp (string)'] = pd.to_datetime(df['order_purchase_timestamp'])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:35.421062Z","iopub.execute_input":"2022-03-03T23:03:35.421396Z","iopub.status.idle":"2022-03-03T23:03:35.468513Z","shell.execute_reply.started":"2022-03-03T23:03:35.42136Z","shell.execute_reply":"2022-03-03T23:03:35.467247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Classifying the customers using *customer_unique_id* by the date they purchased a product.","metadata":{}},{"cell_type":"code","source":"# create a dataframe with unique customer id\n\ndf_user = pd.DataFrame(df['customer_unique_id'])\ndf_user.columns = ['CustomerUniqueID']\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:35.471552Z","iopub.execute_input":"2022-03-03T23:03:35.4719Z","iopub.status.idle":"2022-03-03T23:03:35.491022Z","shell.execute_reply.started":"2022-03-03T23:03:35.471854Z","shell.execute_reply":"2022-03-03T23:03:35.490031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add the max purchase date by customer into a new dataframe","metadata":{}},{"cell_type":"code","source":"max_purchase = df.groupby('customer_unique_id')['order_purchase_timestamp (string)'].max().reset_index()\nmax_purchase.columns = ['CustomerUniqueID','MaxPurchaseDate']\nmax_purchase","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:35.492313Z","iopub.execute_input":"2022-03-03T23:03:35.4928Z","iopub.status.idle":"2022-03-03T23:03:35.717417Z","shell.execute_reply.started":"2022-03-03T23:03:35.492755Z","shell.execute_reply":"2022-03-03T23:03:35.716714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a column **Recency** that is going to take, from the previous dataframe, the oldest order and substract it to the current order date for each customer.\nWe convert the result in days to get the number of days each customers order from the oldest order. ","metadata":{}},{"cell_type":"code","source":"#we take our observation point as the max order date in our dataset using the order_purchase_timestamp variable \n\nmax_purchase['Recency'] = (max_purchase['MaxPurchaseDate'].max() - max_purchase['MaxPurchaseDate']).dt.days\nmax_purchase.sort_values(by=['Recency'])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:35.718535Z","iopub.execute_input":"2022-03-03T23:03:35.718885Z","iopub.status.idle":"2022-03-03T23:03:35.756301Z","shell.execute_reply.started":"2022-03-03T23:03:35.718855Z","shell.execute_reply":"2022-03-03T23:03:35.755418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a dataframe called *df_user* that we'll use to add the results of our RFM clustering. We add the Recency variable to this final dataframe. ","metadata":{}},{"cell_type":"code","source":"df_user = pd.merge(df_user, max_purchase[['CustomerUniqueID', 'MaxPurchaseDate', 'Recency']], on='CustomerUniqueID')\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:35.757792Z","iopub.execute_input":"2022-03-03T23:03:35.758029Z","iopub.status.idle":"2022-03-03T23:03:35.847761Z","shell.execute_reply.started":"2022-03-03T23:03:35.757997Z","shell.execute_reply":"2022-03-03T23:03:35.846791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a graph of the density distribution of the Recency variable through days.","metadata":{}},{"cell_type":"code","source":"# Set notebook mode to work in offline\n\npyoff.init_notebook_mode()\n\n#plot a recency histogram\n\nplot_data = [go.Histogram(x=df_user['Recency'])]\n\nplot_layout = go.Layout(title='Users Recency')\n\nfig = go.Figure(data=plot_data, layout=plot_layout)\n\nfig.update_xaxes(title=\"Days since last purchase\")\n\nfig.update_yaxes(title=\"Number of unique customers\")\n\npyoff.iplot(fig)\n\nfig.write_image(\"recency.png\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:35.84934Z","iopub.execute_input":"2022-03-03T23:03:35.849577Z","iopub.status.idle":"2022-03-03T23:03:37.420723Z","shell.execute_reply.started":"2022-03-03T23:03:35.849549Z","shell.execute_reply":"2022-03-03T23:03:37.419782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Define the best clustering method by using the elbow method \n\nWe iterate the values of k from 2 to 8 and use the Yellowbrick library to return us with the Elbow curve of the WCSS for each k value in the given range.\nThe optimal number of clusters is the point where the curve looks like an elbow.\n\nNote:\nWCSS stands for  Within-Cluster Sum of Square.\nWCSS is the sum of squared distance between each point and the centroid in a cluster.","metadata":{}},{"cell_type":"markdown","source":"Create a liste with a range from 2 to 8 to test the best number of clusters for our models.","metadata":{}},{"cell_type":"code","source":"n_clusters = [2,3,4,5,6,7,8]","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:37.423537Z","iopub.execute_input":"2022-03-03T23:03:37.424196Z","iopub.status.idle":"2022-03-03T23:03:37.42997Z","shell.execute_reply.started":"2022-03-03T23:03:37.424146Z","shell.execute_reply":"2022-03-03T23:03:37.429311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a dataframe that takes the Recency values and use a sample of n = 10000 to use the elbow method on it. ","metadata":{}},{"cell_type":"code","source":"df_recency = df_user[['Recency']].sample(n=10000)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:37.431528Z","iopub.execute_input":"2022-03-03T23:03:37.433Z","iopub.status.idle":"2022-03-03T23:03:37.454622Z","shell.execute_reply.started":"2022-03-03T23:03:37.432959Z","shell.execute_reply":"2022-03-03T23:03:37.453295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The main goal of Kmeans is to find groups in data and the number of groups is represented by K number of clusters. It is an iterative procedure where each data point is assigned to one of the K groups based on features similarity. For instance, we can use the elbow method or the silhouette method to define K number of clusters. ","metadata":{}},{"cell_type":"markdown","source":"We visualize the Elbow method for KMeans clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nkmeans_recency = KMeans(n_clusters = n_clusters)\n\nrecency_visualizer = KElbowVisualizer(kmeans_recency, k=n_clusters, size=(600, 600))\n\nrecency_visualizer.fit(df_recency)    # Fit the data to the visualizer\nfig = recency_visualizer.poof()    # Draw/show/poof the data\n#recency_visualizer.show(outpath=\"kelbow_kmeans.png\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:37.455989Z","iopub.execute_input":"2022-03-03T23:03:37.456515Z","iopub.status.idle":"2022-03-03T23:03:39.373044Z","shell.execute_reply.started":"2022-03-03T23:03:37.456439Z","shell.execute_reply":"2022-03-03T23:03:39.372082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Agglomerative clustering** uses a bottom-up approach, wherein each data point starts in its own cluster. These clusters are then joined greedily, by taking the two most similar clusters together and merging them. We usually draw a dendrogram to visualize the best K number of clusters to choose.","metadata":{}},{"cell_type":"markdown","source":"We visualize the Elbow method for Agglomerative clustering method.","metadata":{}},{"cell_type":"code","source":"agg_recency = AgglomerativeClustering(n_clusters = n_clusters)\n \nrecency_visualizer = KElbowVisualizer(agg_recency, k=n_clusters,  size=(600, 600))\n\nrecency_visualizer.fit(df_recency)    # Fit the data to the visualizer\nfig = recency_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:39.375388Z","iopub.execute_input":"2022-03-03T23:03:39.375911Z","iopub.status.idle":"2022-03-03T23:03:52.014254Z","shell.execute_reply.started":"2022-03-03T23:03:39.375849Z","shell.execute_reply":"2022-03-03T23:03:52.013286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Birch** stands for Balanced Iterative Reducing and Clustering using Hierarchies. It's a clustering algorithm that can cluster large datasets by first generating a small and compact summary of the the large dataset that retains as much information as possible. This smaller summary is then clustered instead of clustering the larger dataset.","metadata":{}},{"cell_type":"markdown","source":"We visualize the Elbow method for Birch clustering method.","metadata":{}},{"cell_type":"code","source":"birch_recency = Birch(n_clusters = n_clusters)\n\nrecency_visualizer = KElbowVisualizer(birch_recency, k=n_clusters,  size=(600, 600))\n\nrecency_visualizer.fit(df_recency)    # Fit the data to the visualizer\nfig = recency_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:52.019457Z","iopub.execute_input":"2022-03-03T23:03:52.019718Z","iopub.status.idle":"2022-03-03T23:03:56.416307Z","shell.execute_reply.started":"2022-03-03T23:03:52.019689Z","shell.execute_reply":"2022-03-03T23:03:56.415287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The **Mini-batch K-means** clustering algorithm is a version of the standard K-means algorithm in machine learning. It uses small, random, fixed-size batches of data to store in memory, and then with each iteration, a random sample of the data is collected and used to update the clusters.","metadata":{}},{"cell_type":"markdown","source":"We visualize the Elbow method for MiniBatchKMeans clustering method.","metadata":{}},{"cell_type":"code","source":"minibatch_recency = MiniBatchKMeans(n_clusters = n_clusters)\n\nrecency_visualizer = KElbowVisualizer(minibatch_recency, k=n_clusters, size=(600, 600))\n\nrecency_visualizer.fit(df_recency)    # Fit the data to the visualizer\nfig = recency_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:56.417653Z","iopub.execute_input":"2022-03-03T23:03:56.417987Z","iopub.status.idle":"2022-03-03T23:03:57.331108Z","shell.execute_reply.started":"2022-03-03T23:03:56.417942Z","shell.execute_reply":"2022-03-03T23:03:57.330144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We notice that k = 4 seems to be the most accurate number of clusters decision.\nWe decide to pick the KMeans method as this is the most commonly used method for RFM segmentation. ","metadata":{}},{"cell_type":"markdown","source":"Fit and predict the number of clusters based on the Recency column. We create a column called RecencyCluster that's going to range from 0 to 3.","metadata":{}},{"cell_type":"code","source":"#build 4 clusters for recency and add it to dataframe\n\nkmeans = KMeans(n_clusters=4)\nkmeans.fit(df_user[['Recency']])\ndf_user['R'] = kmeans.predict(df_user[['Recency']])\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:57.332358Z","iopub.execute_input":"2022-03-03T23:03:57.332642Z","iopub.status.idle":"2022-03-03T23:03:57.887307Z","shell.execute_reply.started":"2022-03-03T23:03:57.332611Z","shell.execute_reply":"2022-03-03T23:03:57.886343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Describe each cluster for the Recency variable ","metadata":{}},{"cell_type":"code","source":"#show details of the dataframe\ndf_user.groupby('R')['Recency'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:57.891387Z","iopub.execute_input":"2022-03-03T23:03:57.89189Z","iopub.status.idle":"2022-03-03T23:03:57.936915Z","shell.execute_reply.started":"2022-03-03T23:03:57.891848Z","shell.execute_reply":"2022-03-03T23:03:57.936076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"frequency\"></a>\n### Frequency","metadata":{}},{"cell_type":"markdown","source":"Create a dictionnary for the new dataframe that will include Frequency as a new variable","metadata":{}},{"cell_type":"code","source":"d = {'index': 'CustomerUniqueID','customer_unique_id': 'Frequency'}","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:57.940682Z","iopub.execute_input":"2022-03-03T23:03:57.941327Z","iopub.status.idle":"2022-03-03T23:03:57.948795Z","shell.execute_reply.started":"2022-03-03T23:03:57.941281Z","shell.execute_reply":"2022-03-03T23:03:57.948085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We count the number of orders per customer_id and return a value_count in a dataframe to know the frequency of order per customer. ","metadata":{}},{"cell_type":"code","source":"#get order counts for each user and create a dataframe with it\n\ndf_frequency = pd.DataFrame(df['customer_unique_id'].value_counts()).reset_index().rename(columns=d)\ndf_frequency","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:57.952962Z","iopub.execute_input":"2022-03-03T23:03:57.953679Z","iopub.status.idle":"2022-03-03T23:03:58.07866Z","shell.execute_reply.started":"2022-03-03T23:03:57.953614Z","shell.execute_reply":"2022-03-03T23:03:58.077953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We merge this dataframe to our RFM dataframe previously containing the Recency clustering. ","metadata":{}},{"cell_type":"code","source":"#add this data to our main dataframe\n\ndf_user = pd.merge(df_user, df_frequency, on='CustomerUniqueID')\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:58.083246Z","iopub.execute_input":"2022-03-03T23:03:58.08582Z","iopub.status.idle":"2022-03-03T23:03:58.19082Z","shell.execute_reply.started":"2022-03-03T23:03:58.085766Z","shell.execute_reply":"2022-03-03T23:03:58.190137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a graph of the density distribution of the Frequency variable among the customers.","metadata":{}},{"cell_type":"code","source":"# Set notebook mode to work in offline\n\npyoff.init_notebook_mode()\n\n#plot the histogram\n\nplot_data = [go.Histogram(x=df_user['Frequency'])]\n\nplot_layout = go.Layout(title='Users Frequency')\n\nfig = go.Figure(data=plot_data, layout=plot_layout)\n\nfig.update_xaxes(title=\"Number of purchases\")\n\nfig.update_yaxes(title=\"Number of unique customers\")\n\npyoff.iplot(fig)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:58.194664Z","iopub.execute_input":"2022-03-03T23:03:58.197083Z","iopub.status.idle":"2022-03-03T23:03:58.432127Z","shell.execute_reply.started":"2022-03-03T23:03:58.197033Z","shell.execute_reply":"2022-03-03T23:03:58.431305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a dataframe that takes the Frequency values and use a sample of n = 10000 to use the elbow method on it. \nWe keep k that range from 2 to 8 clusters for our decision.  ","metadata":{}},{"cell_type":"code","source":"df_frequency = df_user[['Frequency']].sample(n=10000)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:58.43354Z","iopub.execute_input":"2022-03-03T23:03:58.434026Z","iopub.status.idle":"2022-03-03T23:03:58.44889Z","shell.execute_reply.started":"2022-03-03T23:03:58.433993Z","shell.execute_reply":"2022-03-03T23:03:58.446777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for KMeans clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nkmeans_frequency = KMeans(n_clusters = n_clusters)\n\nfrequency_visualizer = KElbowVisualizer(kmeans_frequency, k=n_clusters,  size=(720, 720))\n\nfrequency_visualizer.fit(df_frequency)    # Fit the data to the visualizer\nfig = frequency_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:58.450688Z","iopub.execute_input":"2022-03-03T23:03:58.459448Z","iopub.status.idle":"2022-03-03T23:03:59.758723Z","shell.execute_reply.started":"2022-03-03T23:03:58.459384Z","shell.execute_reply":"2022-03-03T23:03:59.758008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for Agglomerative clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nagg_frequency = AgglomerativeClustering(n_clusters = n_clusters)\n\nfrequency_visualizer = KElbowVisualizer(agg_frequency, k=n_clusters,  size=(720, 720))\n\nfrequency_visualizer.fit(df_frequency)    # Fit the data to the visualizer\nfig = frequency_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:03:59.760021Z","iopub.execute_input":"2022-03-03T23:03:59.764716Z","iopub.status.idle":"2022-03-03T23:04:11.686042Z","shell.execute_reply.started":"2022-03-03T23:03:59.764639Z","shell.execute_reply":"2022-03-03T23:04:11.685163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for Birch clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nbirch_frequency = Birch(n_clusters = n_clusters)\n\nfrequency_visualizer = KElbowVisualizer(birch_frequency, k=n_clusters, size=(720, 720))\n\nfrequency_visualizer.fit(df_frequency)    # Fit the data to the visualizer\nfig = frequency_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:11.687502Z","iopub.execute_input":"2022-03-03T23:04:11.687972Z","iopub.status.idle":"2022-03-03T23:04:14.189307Z","shell.execute_reply.started":"2022-03-03T23:04:11.68791Z","shell.execute_reply":"2022-03-03T23:04:14.188325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, K=4 seems to be the most accurate number of clusters, and we keep KMeans clustering method to keep an harmony in the method used. ","metadata":{}},{"cell_type":"code","source":"kmeans_frequency = KMeans(n_clusters=4)\nkmeans_frequency.fit(df_user[['Frequency']])\ndf_user['F'] = kmeans_frequency.predict(df_user[['Frequency']])\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:14.190784Z","iopub.execute_input":"2022-03-03T23:04:14.191116Z","iopub.status.idle":"2022-03-03T23:04:14.539491Z","shell.execute_reply.started":"2022-03-03T23:04:14.191071Z","shell.execute_reply":"2022-03-03T23:04:14.538805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Describe each cluster for the Frequency variable ","metadata":{}},{"cell_type":"code","source":"#show details of the dataframe\ndf_user.groupby('F')['Frequency'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:14.540885Z","iopub.execute_input":"2022-03-03T23:04:14.542019Z","iopub.status.idle":"2022-03-03T23:04:14.586137Z","shell.execute_reply.started":"2022-03-03T23:04:14.541968Z","shell.execute_reply":"2022-03-03T23:04:14.585317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"monetary-value\"></a>\n### Monetary Value","metadata":{}},{"cell_type":"markdown","source":"Create a dictionnary for the new dataframe that will include Monetary Value as a new variable.","metadata":{}},{"cell_type":"code","source":"d = {'price': 'Monetary Value','customer_unique_id': 'CustomerUniqueID'}","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:14.59029Z","iopub.execute_input":"2022-03-03T23:04:14.590867Z","iopub.status.idle":"2022-03-03T23:04:14.599259Z","shell.execute_reply.started":"2022-03-03T23:04:14.590817Z","shell.execute_reply":"2022-03-03T23:04:14.598332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We sum up the price of each order per customer_id and create a dataframe to know the monetary value per customer. ","metadata":{}},{"cell_type":"code","source":"# calculate revenue for each customer\n\ndf_revenue = df.groupby('customer_unique_id').price.sum().reset_index().rename(columns=d)\ndf_revenue","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:14.603884Z","iopub.execute_input":"2022-03-03T23:04:14.606677Z","iopub.status.idle":"2022-03-03T23:04:14.874876Z","shell.execute_reply.started":"2022-03-03T23:04:14.606621Z","shell.execute_reply":"2022-03-03T23:04:14.874207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We merge this dataframe to our RFM dataframe previously containing the Recency and Frequency clusterings. ","metadata":{}},{"cell_type":"code","source":"#add this data to our main dataframe\n\ndf_user = pd.merge(df_user, df_revenue, on='CustomerUniqueID')\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:14.879022Z","iopub.execute_input":"2022-03-03T23:04:14.881015Z","iopub.status.idle":"2022-03-03T23:04:14.995857Z","shell.execute_reply.started":"2022-03-03T23:04:14.880963Z","shell.execute_reply":"2022-03-03T23:04:14.995159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a graph of the density distribution of the Monetary Value variable among the customers.","metadata":{}},{"cell_type":"code","source":"# Set notebook mode to work in offline\n\npyoff.init_notebook_mode()\n\n#plot the histogram\n\nplot_data = [go.Histogram(x=df_user['Monetary Value'])]\n\nplot_layout = go.Layout(title='Users Monetary Value')\n\nfig = go.Figure(data=plot_data, layout=plot_layout)\n\nfig.update_xaxes(title=\"Monetary value\")\n\nfig.update_yaxes(title=\"Number of unique customers\")\n\npyoff.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:14.999973Z","iopub.execute_input":"2022-03-03T23:04:15.001946Z","iopub.status.idle":"2022-03-03T23:04:15.348252Z","shell.execute_reply.started":"2022-03-03T23:04:15.001898Z","shell.execute_reply":"2022-03-03T23:04:15.347331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a dataframe that takes the Revenue values and use a sample of n = 10000 to use the elbow method on it. \nWe keep k that range from 2 to 8 clusters for our decision.  ","metadata":{}},{"cell_type":"code","source":"df_revenue = df_user[['Monetary Value']].sample(n=10000)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:15.349732Z","iopub.execute_input":"2022-03-03T23:04:15.35032Z","iopub.status.idle":"2022-03-03T23:04:15.372297Z","shell.execute_reply.started":"2022-03-03T23:04:15.350276Z","shell.execute_reply":"2022-03-03T23:04:15.371287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for KMeans clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nkmeans_revenue = KMeans(n_clusters = n_clusters)\n\nrevenue_visualizer = KElbowVisualizer(kmeans_revenue, k=n_clusters,  size=(720, 720))\n\nrevenue_visualizer.fit(df_revenue)    # Fit the data to the visualizer\nfig = revenue_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:15.37375Z","iopub.execute_input":"2022-03-03T23:04:15.37424Z","iopub.status.idle":"2022-03-03T23:04:16.878483Z","shell.execute_reply.started":"2022-03-03T23:04:15.374186Z","shell.execute_reply":"2022-03-03T23:04:16.877371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for Agglomerative clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nagg_revenue = AgglomerativeClustering(n_clusters = n_clusters)\n\nrevenue_visualizer = KElbowVisualizer(agg_revenue, k=n_clusters,  size=(720, 720))\n\nrevenue_visualizer.fit(df_revenue)    # Fit the data to the visualizer\nfig = revenue_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:16.882902Z","iopub.execute_input":"2022-03-03T23:04:16.883237Z","iopub.status.idle":"2022-03-03T23:04:41.884312Z","shell.execute_reply.started":"2022-03-03T23:04:16.883189Z","shell.execute_reply":"2022-03-03T23:04:41.883315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for Birch clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nbirch_revenue = Birch(n_clusters = n_clusters)\n\nrevenue_visualizer = KElbowVisualizer(birch_revenue, k=n_clusters,  size=(720, 720))\n\nrevenue_visualizer.fit(df_revenue)    # Fit the data to the visualizer\nfig = revenue_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:41.886003Z","iopub.execute_input":"2022-03-03T23:04:41.88645Z","iopub.status.idle":"2022-03-03T23:04:46.236186Z","shell.execute_reply.started":"2022-03-03T23:04:41.886401Z","shell.execute_reply":"2022-03-03T23:04:46.235315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for MiniBatchKMeans clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nminibatch_revenue = MiniBatchKMeans(n_clusters = n_clusters)\n\nrevenue_visualizer = KElbowVisualizer(minibatch_revenue, k=n_clusters,  size=(720, 720))\n\nrevenue_visualizer.fit(df_revenue)    # Fit the data to the visualizer\nfig = revenue_visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:46.23774Z","iopub.execute_input":"2022-03-03T23:04:46.238267Z","iopub.status.idle":"2022-03-03T23:04:47.088532Z","shell.execute_reply.started":"2022-03-03T23:04:46.238193Z","shell.execute_reply":"2022-03-03T23:04:47.087497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, K=4 seems to be the most accurate number of clusters, and we keep KMeans clustering method to keep an harmony in the method used. ","metadata":{}},{"cell_type":"code","source":"kmeans_revenue = KMeans(n_clusters=4)\nkmeans_revenue.fit(df_user[['Monetary Value']])\ndf_user['M'] = kmeans_revenue.predict(df_user[['Monetary Value']])\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:47.090126Z","iopub.execute_input":"2022-03-03T23:04:47.090422Z","iopub.status.idle":"2022-03-03T23:04:47.600798Z","shell.execute_reply.started":"2022-03-03T23:04:47.090387Z","shell.execute_reply":"2022-03-03T23:04:47.60008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Describe each cluster for the Monetary Value variable ","metadata":{}},{"cell_type":"code","source":"#show details of the dataframe\ndf_user.groupby('M')['Monetary Value'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:47.602321Z","iopub.execute_input":"2022-03-03T23:04:47.602839Z","iopub.status.idle":"2022-03-03T23:04:47.645028Z","shell.execute_reply.started":"2022-03-03T23:04:47.602798Z","shell.execute_reply":"2022-03-03T23:04:47.644285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"other-variables\"></a>\n## Other Variables\n\nWe consider adding other variables to our RFM segmentation.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:47.646629Z","iopub.execute_input":"2022-03-03T23:04:47.647157Z","iopub.status.idle":"2022-03-03T23:04:47.698254Z","shell.execute_reply.started":"2022-03-03T23:04:47.647117Z","shell.execute_reply":"2022-03-03T23:04:47.697276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"review-score\"></a>\n### Review Score","metadata":{}},{"cell_type":"code","source":"d = {'review_score': 'Review Score','customer_unique_id': 'CustomerUniqueID'}","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:47.702542Z","iopub.execute_input":"2022-03-03T23:04:47.705633Z","iopub.status.idle":"2022-03-03T23:04:47.710851Z","shell.execute_reply.started":"2022-03-03T23:04:47.705573Z","shell.execute_reply":"2022-03-03T23:04:47.709795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate reviews for each customer\n\ndf_reviews = df[['customer_unique_id','review_score']].sort_values(by='review_score', ascending=False).rename(columns=d)\ndf_reviews","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:47.720074Z","iopub.execute_input":"2022-03-03T23:04:47.720814Z","iopub.status.idle":"2022-03-03T23:04:47.761264Z","shell.execute_reply.started":"2022-03-03T23:04:47.720759Z","shell.execute_reply":"2022-03-03T23:04:47.760333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#add this data to our main dataframe\n\ndf_user = pd.merge(df_user, df_reviews, on='CustomerUniqueID')\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:47.762973Z","iopub.execute_input":"2022-03-03T23:04:47.763559Z","iopub.status.idle":"2022-03-03T23:04:47.893477Z","shell.execute_reply.started":"2022-03-03T23:04:47.763509Z","shell.execute_reply":"2022-03-03T23:04:47.892446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set notebook mode to work in offline\n\npyoff.init_notebook_mode()\n\n#plot the histogram\n\nplot_data = [go.Histogram(x=df_user['Review Score'])]\n\nplot_layout = go.Layout(title='Users Review Score')\n\nfig = go.Figure(data=plot_data, layout=plot_layout)\n\nfig.update_xaxes(title=\"Review Score\")\n\nfig.update_yaxes(title=\"Number of unique customers\")\n\npyoff.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:47.897368Z","iopub.execute_input":"2022-03-03T23:04:47.899172Z","iopub.status.idle":"2022-03-03T23:04:48.194545Z","shell.execute_reply.started":"2022-03-03T23:04:47.899127Z","shell.execute_reply":"2022-03-03T23:04:48.193657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"freight-value\"></a>\n### Freight Value","metadata":{}},{"cell_type":"code","source":"d = {'freight_value': 'Freight Value','customer_unique_id': 'CustomerUniqueID'}","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:48.196418Z","iopub.execute_input":"2022-03-03T23:04:48.197026Z","iopub.status.idle":"2022-03-03T23:04:48.211487Z","shell.execute_reply.started":"2022-03-03T23:04:48.196979Z","shell.execute_reply":"2022-03-03T23:04:48.210606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate reviews for each order\n\ndf_freight = df[['customer_unique_id','freight_value']].sort_values(by='freight_value', ascending=False).rename(columns=d)\ndf_freight","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:48.212984Z","iopub.execute_input":"2022-03-03T23:04:48.213298Z","iopub.status.idle":"2022-03-03T23:04:48.327001Z","shell.execute_reply.started":"2022-03-03T23:04:48.213258Z","shell.execute_reply":"2022-03-03T23:04:48.325961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#add this data to our main dataframe\n\ndf_user = pd.merge(df_user, df_freight, on='CustomerUniqueID')\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:48.328371Z","iopub.execute_input":"2022-03-03T23:04:48.328821Z","iopub.status.idle":"2022-03-03T23:04:48.643435Z","shell.execute_reply.started":"2022-03-03T23:04:48.328691Z","shell.execute_reply":"2022-03-03T23:04:48.642721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set notebook mode to work in offline\n\npyoff.init_notebook_mode()\n\n#plot the histogram\n\nplot_data = [go.Histogram(x=df_user['Freight Value'])]\n\nplot_layout = go.Layout(title='Users Freight Value')\n\nfig = go.Figure(data=plot_data, layout=plot_layout)\n\nfig.update_xaxes(title=\"Freight Value\")\n\nfig.update_yaxes(title=\"Number of unique customers\")\n\npyoff.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:48.647076Z","iopub.execute_input":"2022-03-03T23:04:48.648866Z","iopub.status.idle":"2022-03-03T23:04:50.134539Z","shell.execute_reply.started":"2022-03-03T23:04:48.648824Z","shell.execute_reply":"2022-03-03T23:04:50.133534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"delay-date\"></a>\n### Delay Date","metadata":{}},{"cell_type":"markdown","source":"<a id=\"rfm-normalization\"></a>\n## RFM Normalization\nWe want to have an overview of each variable using boxplots representations. We first need to normalize our data and by transforming the variables using StandardScaler() from scikit-learn library so the values are closer to each other.  \n\nStandardizing the data allows us to not biased the clustering segmentation. For instance, the variable Revenue has higher values scale than Frequency and Recency. ","metadata":{}},{"cell_type":"code","source":"# get the three variables into a dataframe to apply transformation\nrfm = df_user[['Recency','Frequency','Monetary Value', 'Review Score', 'Freight Value']]\nrfm","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:32.209762Z","iopub.execute_input":"2022-03-03T23:05:32.210114Z","iopub.status.idle":"2022-03-03T23:05:32.291497Z","shell.execute_reply.started":"2022-03-03T23:05:32.210077Z","shell.execute_reply":"2022-03-03T23:05:32.29055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We transform the RFM value to a logarithmic scale ","metadata":{}},{"cell_type":"code","source":"# apply logarithmic transformation to get the same scale\nrfm_log = np.log(rfm)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:32.584275Z","iopub.execute_input":"2022-03-03T23:05:32.58484Z","iopub.status.idle":"2022-03-03T23:05:32.658993Z","shell.execute_reply.started":"2022-03-03T23:05:32.584795Z","shell.execute_reply":"2022-03-03T23:05:32.658276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We replace the 0 value to avoid getting infinite values after using a logarithmic transformation. ","metadata":{}},{"cell_type":"code","source":"rfm_log = rfm_log.replace([np.inf, -np.inf], 0)\nrfm_log = pd.DataFrame(data = rfm_log, \n                            index = df_user.index, \n                            ) \nrfm_log","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:32.922975Z","iopub.execute_input":"2022-03-03T23:05:32.923299Z","iopub.status.idle":"2022-03-03T23:05:33.014338Z","shell.execute_reply.started":"2022-03-03T23:05:32.923266Z","shell.execute_reply":"2022-03-03T23:05:33.013438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We use StandardScaler() to standardize out data before using a clustering method on the three RFM variables in order to get our final cluster of clients.","metadata":{}},{"cell_type":"code","source":"# standardization of the three variables between each other to not biased the clustering method\nscaler = StandardScaler()\nrfm_standard = scaler.fit_transform(rfm_log)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:33.27318Z","iopub.execute_input":"2022-03-03T23:05:33.273512Z","iopub.status.idle":"2022-03-03T23:05:33.429502Z","shell.execute_reply.started":"2022-03-03T23:05:33.273477Z","shell.execute_reply":"2022-03-03T23:05:33.428506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a dataframe ready for clustering","metadata":{}},{"cell_type":"code","source":"#turn the processed data back into a dataframe\nrfm_standard = pd.DataFrame(data = rfm_standard, \n                            index = df_user.index, \n                            ) \nrfm_standard.columns = ['Recency_standard', 'Frequency_standard', 'Monetary_value_standard', 'Review_score_standard', 'Freight_value_standard']\nrfm_standard","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:33.624165Z","iopub.execute_input":"2022-03-03T23:05:33.624482Z","iopub.status.idle":"2022-03-03T23:05:33.643909Z","shell.execute_reply.started":"2022-03-03T23:05:33.624446Z","shell.execute_reply":"2022-03-03T23:05:33.642767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observe the three RFM variables before clustering.\nRecency variable observation at the logarithmic scale.","metadata":{}},{"cell_type":"code","source":"# Recency\n\n# boxplot \n\nfig = plt.figure(figsize =([8, 8])) \nsns.set_style('darkgrid')\nplt.style.use('ggplot')\nsns.boxplot(x=rfm_standard['Recency_standard'],color=\"blue\", orient=\"h\")\nplt.xlabel(\"Days of last purchase\", size=16)\nplt.title(\"Distribution of the Recency variable (log)\", size=18, y=1.03)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:35.209725Z","iopub.execute_input":"2022-03-03T23:05:35.210931Z","iopub.status.idle":"2022-03-03T23:05:35.611192Z","shell.execute_reply.started":"2022-03-03T23:05:35.210877Z","shell.execute_reply":"2022-03-03T23:05:35.610546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Frequency variable observation at the logarithmic scale.","metadata":{}},{"cell_type":"code","source":"# Frequency\n\n# boxplot\n\nfig = plt.figure(figsize =([8, 8])) \nsns.set_style('darkgrid')\nplt.style.use('ggplot')\nsns.boxplot(x=rfm_standard['Frequency_standard'],color=\"blue\", orient=\"h\")\nplt.xlabel(\"Number of orders\", size=16)\nplt.title(\"Distribution of the Frequency variable (log)\", size=18, y=1.03)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:35.890324Z","iopub.execute_input":"2022-03-03T23:05:35.890751Z","iopub.status.idle":"2022-03-03T23:05:36.1019Z","shell.execute_reply.started":"2022-03-03T23:05:35.890719Z","shell.execute_reply":"2022-03-03T23:05:36.101046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Monetary value variable observation at the logarithmic scale.","metadata":{}},{"cell_type":"code","source":"# Revenue\n\n# boxplot\n\nfig = plt.figure(figsize =([8, 8])) \nsns.set_style('darkgrid')\nplt.style.use('ggplot')\nsns.boxplot(x=rfm_standard['Monetary_value_standard'],color=\"blue\", orient=\"h\")\nplt.xlabel(\"Monetary value\", size=16)\nplt.title(\"Distribution of the Monetary Value variable (log)\", size=18, y=1.03)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:36.25142Z","iopub.execute_input":"2022-03-03T23:05:36.25185Z","iopub.status.idle":"2022-03-03T23:05:36.470862Z","shell.execute_reply.started":"2022-03-03T23:05:36.251817Z","shell.execute_reply":"2022-03-03T23:05:36.469954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reviews\n\n# boxplot\n\nfig = plt.figure(figsize =([8, 8])) \nsns.set_style('darkgrid')\nplt.style.use('ggplot')\nsns.boxplot(x=rfm_standard['Review_score_standard'],color=\"blue\", orient=\"h\")\nplt.xlabel(\"Review score\", size=16)\nplt.title(\"Distribution of the Review Score variable (log)\", size=18, y=1.03)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:36.472423Z","iopub.execute_input":"2022-03-03T23:05:36.472665Z","iopub.status.idle":"2022-03-03T23:05:37.12651Z","shell.execute_reply.started":"2022-03-03T23:05:36.472635Z","shell.execute_reply":"2022-03-03T23:05:37.125865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freight\n\n# boxplot\n\nfig = plt.figure(figsize =([8, 8])) \nsns.set_style('darkgrid')\nplt.style.use('ggplot')\nsns.boxplot(x=rfm_standard['Freight_value_standard'],color=\"blue\", orient=\"h\")\nplt.xlabel(\"Freight Value\", size=16)\nplt.title(\"Distribution of the Freight Value variable (log)\", size=18, y=1.03)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:37.127934Z","iopub.execute_input":"2022-03-03T23:05:37.128179Z","iopub.status.idle":"2022-03-03T23:05:37.476644Z","shell.execute_reply.started":"2022-03-03T23:05:37.128149Z","shell.execute_reply":"2022-03-03T23:05:37.475624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"customers-segmentation\"></a>\n## Customers Segmentation","metadata":{}},{"cell_type":"markdown","source":"Create a sample of the transformed RFM variables to test the Elbow method on different clustering methods. ","metadata":{}},{"cell_type":"code","source":"rfm_sample = rfm_standard.sample(n=10000)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:37.477906Z","iopub.execute_input":"2022-03-03T23:05:37.47816Z","iopub.status.idle":"2022-03-03T23:05:37.538792Z","shell.execute_reply.started":"2022-03-03T23:05:37.478127Z","shell.execute_reply":"2022-03-03T23:05:37.537508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for KMeans clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nkmeans_cluster = KMeans(n_clusters = n_clusters)\n\nvisualizer = KElbowVisualizer(kmeans_cluster, k=n_clusters,  size=(720, 720))\n\nvisualizer.fit(rfm_sample)    # Fit the data to the visualizer\nfig = visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:37.541122Z","iopub.execute_input":"2022-03-03T23:05:37.541804Z","iopub.status.idle":"2022-03-03T23:05:47.765254Z","shell.execute_reply.started":"2022-03-03T23:05:37.541747Z","shell.execute_reply":"2022-03-03T23:05:47.764343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for Agglomerative clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nagg_cluster = AgglomerativeClustering(n_clusters = n_clusters)\n\nvisualizer = KElbowVisualizer(agg_cluster, k=n_clusters,  size=(720, 720))\n\nvisualizer.fit(rfm_sample)    # Fit the data to the visualizer\nfig = visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:05:47.769437Z","iopub.execute_input":"2022-03-03T23:05:47.770192Z","iopub.status.idle":"2022-03-03T23:06:13.12602Z","shell.execute_reply.started":"2022-03-03T23:05:47.770149Z","shell.execute_reply":"2022-03-03T23:06:13.125074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for Birch clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nbirch_cluster = Birch(n_clusters = n_clusters)\n\nvisualizer = KElbowVisualizer(birch_cluster, k=n_clusters,  size=(720, 720))\n\nvisualizer.fit(rfm_sample)    # Fit the data to the visualizer\nfig = visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:13.127419Z","iopub.execute_input":"2022-03-03T23:06:13.127672Z","iopub.status.idle":"2022-03-03T23:06:20.148218Z","shell.execute_reply.started":"2022-03-03T23:06:13.127642Z","shell.execute_reply":"2022-03-03T23:06:20.147249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We visualize the Elbow method for MiniBatchKMeans clustering method.","metadata":{}},{"cell_type":"code","source":"# Instantiate the clustering model and visualizer\n\nminibatch_cluster = MiniBatchKMeans(n_clusters = n_clusters)\n\nvisualizer = KElbowVisualizer(minibatch_cluster, k=n_clusters,  size=(720, 720))\n\nvisualizer.fit(rfm_sample)    # Fit the data to the visualizer\nfig = visualizer.poof()    # Draw/show/poof the data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:20.150755Z","iopub.execute_input":"2022-03-03T23:06:20.151744Z","iopub.status.idle":"2022-03-03T23:06:21.551519Z","shell.execute_reply.started":"2022-03-03T23:06:20.15169Z","shell.execute_reply":"2022-03-03T23:06:21.550921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We notice that K=4 or 5 depending on the clustering method we decide to use. We decide to go with KMeans again, but we could have gone with Agglomerative clustering. ","metadata":{}},{"cell_type":"code","source":"kmeans_cluster = KMeans(n_clusters=4)\nkmeans_cluster.fit(rfm_standard)\nrfm_standard['RFM Clusters'] = kmeans_cluster.predict(rfm_standard)\nrfm_standard","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:21.55336Z","iopub.execute_input":"2022-03-03T23:06:21.553964Z","iopub.status.idle":"2022-03-03T23:06:29.608979Z","shell.execute_reply.started":"2022-03-03T23:06:21.553916Z","shell.execute_reply":"2022-03-03T23:06:29.608165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We reindex the RFM clusters to each customer_id entry in our df_user main dataframe. ","metadata":{}},{"cell_type":"code","source":"df_user = pd.concat([df_user, rfm_standard], axis=1)\ndf_user","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:29.610729Z","iopub.execute_input":"2022-03-03T23:06:29.61138Z","iopub.status.idle":"2022-03-03T23:06:29.715699Z","shell.execute_reply.started":"2022-03-03T23:06:29.611331Z","shell.execute_reply":"2022-03-03T23:06:29.714887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a dataframe that contains our RFM Clusters ordered from the best customers to the least one so we can make a segmentation.","metadata":{}},{"cell_type":"code","source":"#segmentation using mean() to see details\n\ncustomer_segments = df_user.groupby('RFM Clusters')['Recency','Frequency','Monetary Value','Review Score','Freight Value'].mean()\ncustomer_segments.sort_values(by=['Frequency'], ascending=False)\ncustomer_segments.sort_values(by=['Monetary Value'], ascending=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:29.719677Z","iopub.execute_input":"2022-03-03T23:06:29.721587Z","iopub.status.idle":"2022-03-03T23:06:29.908285Z","shell.execute_reply.started":"2022-03-03T23:06:29.721538Z","shell.execute_reply":"2022-03-03T23:06:29.907573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create an overall score that shows us the sum of the three cluster for each customer. \n\nFrom this, we have four groups of typical customers based on recency, frequency and revenue scoring. \n\nFrom now on, we can create segments of customers using this scoring. \n\nBy reading our scope of work, we understand that Olist is looking for the customers that bring them the best monetary value and frequency of order so we're going to order our segments keeping these info in mind. \n\nFrom the best groups of customers to the worst, we call the segments as followed:\n\n- **Diamond**\n- **Gold**\n- **Silver**\n- **Bronze**","metadata":{}},{"cell_type":"code","source":"df_user.loc[df_user['RFM Clusters']== 0,'Segment'] = 'Bronze'\ndf_user.loc[df_user['RFM Clusters']== 2,'Segment'] = 'Silver' \ndf_user.loc[df_user['RFM Clusters']== 3,'Segment'] = 'Gold' \ndf_user.loc[df_user['RFM Clusters']== 1,'Segment'] = 'Diamond'","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:29.912145Z","iopub.execute_input":"2022-03-03T23:06:29.914004Z","iopub.status.idle":"2022-03-03T23:06:30.168491Z","shell.execute_reply.started":"2022-03-03T23:06:29.913962Z","shell.execute_reply":"2022-03-03T23:06:30.167724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a dataframe to store the count of each segment of customers.","metadata":{}},{"cell_type":"code","source":"segments_counts = df_user['Segment'].value_counts().sort_values(ascending=True)\nsegments_counts","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:30.172933Z","iopub.execute_input":"2022-03-03T23:06:30.174832Z","iopub.status.idle":"2022-03-03T23:06:30.35126Z","shell.execute_reply.started":"2022-03-03T23:06:30.174787Z","shell.execute_reply":"2022-03-03T23:06:30.35047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We notice that the best customers of Olist represent the **Diamond (12.85%) + Gold (35.19%) = 48.04%**.\nThe least interesting customers represent the **Bronze (34.91%)**.","metadata":{}},{"cell_type":"code","source":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\n\nfig, ax = plt.subplots(figsize=(10, 10))\nbars = ax.barh(range(len(segments_counts)), segments_counts, color='purple')\nplt.title(\"Customers repartition per segment\", size=22, y=1.03)\nplt.xlabel(\"Customers base\", size=18)\nplt.ylabel(\"% Customers per segment\", size=18)\nax.tick_params(left=False, bottom=False, labelbottom=False)\nax.set_yticks(range(len(segments_counts)))\nax.set_yticklabels(segments_counts.index,  fontsize = 14)\n\nfor i, bar in enumerate(bars):\n        value = bar.get_width()\n        ax.text(value,bar.get_y() + bar.get_height()/2,'{:,} ({:,.2f}%)'.format(int(value),\n                float(value*100/segments_counts.sum())),\n                va='center',\n                ha='left'\n               )\n\nplt.savefig('count_segmentation.png', dpi=300, format='png', bbox_inches='tight') # don't crop the legend while saving the figure\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:30.356185Z","iopub.execute_input":"2022-03-03T23:06:30.358388Z","iopub.status.idle":"2022-03-03T23:06:31.263654Z","shell.execute_reply.started":"2022-03-03T23:06:30.358339Z","shell.execute_reply":"2022-03-03T23:06:31.26247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"graphic-representations\"></a>\n## Graphic representations\n\nWe'll use Plotly library to represent our segments in a 2D and 3D graph using the standardized variables for a better representation.","metadata":{}},{"cell_type":"code","source":"# Set notebook mode to work in offline\n\npyoff.init_notebook_mode()\n\nfig = px.scatter_3d(\n    df_user, x=\"Recency_standard\", y=\"Frequency_standard\", z=\"Monetary_value_standard\", color='Segment',\n    title='3D representation for RFM segments KMeans-based clustering', opacity = 0.7)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:31.265174Z","iopub.execute_input":"2022-03-03T23:06:31.265553Z","iopub.status.idle":"2022-03-03T23:06:43.970565Z","shell.execute_reply.started":"2022-03-03T23:06:31.265494Z","shell.execute_reply":"2022-03-03T23:06:43.968579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set notebook mode to work in offline\n\npyoff.init_notebook_mode()\n\nfig = px.scatter(\n    df_user, x=\"Recency_standard\", y=\"Frequency_standard\", color='Segment',\n    title='Recency VS Frequency for RFM segments KMeans-based clustering',\n)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:06:43.972614Z","iopub.execute_input":"2022-03-03T23:06:43.973401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set notebook mode to work in offline\n\npyoff.init_notebook_mode()\n\nfig = px.scatter(\n    df_user, x=\"Recency_standard\", y=\"Monetary_value_standard\", color='Segment',\n    title='Recency VS Monetary Value for RFM segments KMeans-based clustering',\n)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set notebook mode to work in offline\n\npyoff.init_notebook_mode()\n\nfig = px.scatter(\n    df_user, x=\"Frequency_standard\", y=\"Monetary_value_standard\", color='Segment',\n    title='Frequency VS Monetary Value for RFM segments KMeans-based clustering',\n)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"production\"></a>\n## Prepare for Production","metadata":{}},{"cell_type":"code","source":"os.chdir(r'./')\ndf_user.to_csv('df_segmentation.csv',sep = '\\t',index = True)\nfrom IPython.display import FileLink\nFileLink(r'df_segmentation.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T23:04:50.578392Z","iopub.status.idle":"2022-03-03T23:04:50.578889Z","shell.execute_reply.started":"2022-03-03T23:04:50.57862Z","shell.execute_reply":"2022-03-03T23:04:50.578646Z"},"trusted":true},"execution_count":null,"outputs":[]}]}